{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from neural_network import build_model,predict,plot_decision_boundary\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(200,noise=0.20)\n",
    "nn_hdim =4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z))\n",
    "    soft_max = np.amax(exp_z / np.sum(exp_z))\n",
    "    return soft_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_initialization(x_shape, nndim, y_shape):\n",
    "    W1 = np.random.randn(x_shape, nndim)\n",
    "    b1 = np.zeros((1,nndim))\n",
    "    W2 = np.random.randn(nndim,y_shape)\n",
    "    b2 = np.zeros((1,y_shape))\n",
    "    parameters = {\n",
    "        \"W1\": W1,\n",
    "        \"b1\" : b1,\n",
    "        \"W2\": W2,\n",
    "        \"b2\" : b2\n",
    "      }\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = weight_initialization(X.shape[1], nn_hdim, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedfoward(X,W1,W2,b1,b2):\n",
    "        a = np.dot(X,W1) + b1\n",
    "        #print(a.shape)\n",
    "        h = np.tanh(a)\n",
    "        #print(h.shape)\n",
    "        z = np.dot(h,W2) + b2\n",
    "        #print(z.shape)\n",
    "        y_pred = softmax(z)\n",
    "        #print(y_pred.shape)\n",
    "        return a,h,z,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "print(X[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2952442   0.19640692 -0.27152204 -0.5473562 ]] [[-0.2869544   0.19391978 -0.26504053 -0.49853611]] [[1.16679589 0.36707584]] 0.6899145925636443\n"
     ]
    }
   ],
   "source": [
    "a,h,z,y_pred = feedfoward(X[1],parameters['W1'],parameters['W2'],parameters['b1'],parameters['b2'])\n",
    "print(a,h,z,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model,X, y):\n",
    "    W1, W2, b1, b2 = model['W1'], model['W2'], model['b1'], model['b2']\n",
    "    a,h,z,y_pred = feedfoward(X,W1,W2,b1,b2)\n",
    "    if y_pred==0:\n",
    "        logY = np.multiply(y, 0)\n",
    "        logY_= np.multiplty(1-y,np.log2(1-y_pred))\n",
    "        loss = -np.sum(logY + logY_)/2 \n",
    "    elif y_pred==1:\n",
    "        logY = np.multiply(y, np.log2(y_pred))\n",
    "        logY_ = np.multiply(1-y,0)\n",
    "        loss = -np.sum(logY + logY_)/2 \n",
    "    else:\n",
    "        loss = -np.sum(np.multiply(y, np.log(y_pred)) +  np.multiply(1-y, np.log(1-y_pred)))/X.shape[0]\n",
    "    \n",
    "    #print (loss)\n",
    "    #cost = -np.sum(np.multiply(Y, np.log(A2)) +  np.multiply(1-Y, np.log(1-A2)))/m\n",
    "    loss = np.squeeze(loss)\n",
    "    cost = {\n",
    "    \"a\": a,\n",
    "    \"h\": h,\n",
    "    \"z\": z,\n",
    "    \"y_pred\": y_pred,\n",
    "    \"loss\":loss\n",
    "    }\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5854537557945271\n"
     ]
    }
   ],
   "source": [
    "cost = calculate_loss(parameters,X[1], y[1])\n",
    "print(cost['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(X, Y, cost, parameters):\n",
    "    a = cost['a']\n",
    "    h = cost['h'] \n",
    "    y_pred = cost['y_pred']\n",
    "    W2 = parameters['W2']\n",
    "    X = np.reshape(X,(1,2))\n",
    "    dZ2 = np.subtract(y_pred,Y)\n",
    "    dW2 = np.dot(h.T,dZ2)\n",
    "    db2 = dZ2#np.sum(dZ2, axis=1, keepdims=True)/m\n",
    "    dZ1 = np.multiply(np.dot(dZ2,W2.T), 1-np.power(np.tanh(a),2))\n",
    "    dW1 = np.dot(X.T,dZ1)\n",
    "    db1 = dZ1#np.sum(dZ1, axis=1, keepdims=True)/m\n",
    "\n",
    "    grads = {\n",
    "    \"dW1\": dW1,\n",
    "    \"db1\": db1,\n",
    "    \"dW2\": dW2,\n",
    "    \"db2\": db2\n",
    "    }\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "\n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "\n",
    "    new_parameters = {\n",
    "    \"W1\": W1,\n",
    "    \"W2\": W2,\n",
    "    \"b1\" : b1,\n",
    "    \"b2\" : b2\n",
    "    }\n",
    "\n",
    "    return new_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(X, y, nn_hdim, num_passes=20000, print_loss=False):\n",
    "    c= 0\n",
    "    learning_rate = 0.1\n",
    "    parameters= weight_initialization(X.shape[1], nn_hdim, 1)\n",
    "    for i in range(num_passes):\n",
    "        if i % X.shape[0]-1==0:\n",
    "            c = 0\n",
    "        cost = calculate_loss(parameters,X[c],y[c])\n",
    "        if print_loss == True:\n",
    "            print(cost['loss'])\n",
    "        grads = backward_prop(X[c], y[c], cost, parameters)\n",
    "        parameters= update_parameters(parameters, grads, learning_rate)\n",
    "        print(c)\n",
    "        print(i)\n",
    "        c = c +1\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
